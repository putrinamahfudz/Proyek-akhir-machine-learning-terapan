# -*- coding: utf-8 -*-
"""ProyekAkhirMLT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cEU7ZnSMAhwVmGzZOeF5KtqiWTCkrzTO

## **PUTRI NUR AINI MAHFUDZ (M203Y0411)**

## **Proyek Akhir Kelas Machine Learning Terapan**

---

## **Latar Belakang**

Di zaman digital ini, hal yang menjadi tuntutan perkembangan globalisasi adalah literasi. Kemajuan zaman dan cara berliterasi harus seimbang. Terutama bagi generasi mellenial atau yang dikenal sebagai generasi digital. Di era digital harus memberikan sumbangan berupa kesadaran akan pentingnya pengetahuan yang mendalam.

Pada zaman yang dipenuhi oleh penerapan teknologi ini harusnya dapat lebih mudah dan cepat dalam meningkatan budaya literasi di setiap tempat, salah satunya dengan membaca buku melalui perpustakaan online. Agar user memiliki pengalaman pengguna yang baik dalam menggunakan perpustakaan online, maka perlu  diterapkan salah satu hasil produk dari *machine learning* yaitu sistem rekomendasi untuk memudahkan user memilih buku yang diminati untuk dibaca.

Oleh karena itu, saya berniat untuk membuat sistem rekomendasi buku yang kelak bisa diterapkan pada aplikasi semacam perpustakaan online.

## **Bussiness Understanding**

### Problem Statements
Berdasarkan latar belakang di atas, berikut ini rumusan masalah yang dapat diselesaikan pada proyek ini:
- Bagaimana cara melakukan pengolahan data pada dataset Books.csv, Ratings.csv, dan Users.csv agar dapat digunakan pada model *machine learning*?
- Bagaimana cara membuat model *machine learning* untuk merekomendasikan buku dengan menggunakan *collaborative filtering*?

### Goals
Tujuan dari proyek ini adalah:
- Mengetahui cara melakukan pengolahan terhadap dataset Books.csv, Ratings.csv, dan Users.csv.
- Mengetahui cara membuat model *machine learning* untuk merekomendasikan buku dengan menggunakan *collaborative filtering*.

### Solution Statements
Pada proyek ini, saya akan membuat sistem rekomendasi dengan menggunakan *collaborative filtering*.

*Collaborative Filtering* adalah sebuah metode yang merekomendasikan item berdasarkan kemiripan user dalam hal memilih atau memberi nilai kepada item.

Kelebihan dari metode ini adalah hasil rekomendasi yang beragam dan bersifat relevan dan baru, sedangkan kekurangan dari metode ini yaitu tidak dapat menghasilkan rekomendasi dikarenakan tidak adanya informasi preferensi untuk pengguna baru dan item baru *(cold-start problem)*.

### Impor library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

"""## **Data Understanding**

Dalam dataset ini terdapat 3 file csv, di antaranya:
1. Books.csv

  Penjelasan mengenai variabel yang ada pada dataset Books.csv adalah sebagai berikut: 

  - ISBN: merupakan kode ISBN dari buku
  - Book-Title: merupakan judul dari buku
  - Book-Author: merupakan author atau penulis dari buku
  - Year-Of-Publication: merupakan tahun terbit dari buku  
  - Publisher: merupakan publisher atau penerbit dari buku  
  - Image-URL-S: merupakan URL yg menunjukkan foto buku berukuran small
  - Image-URL-M: merupakan URL yg menunjukkan foto buku berukuran medium
  - Image-URL-L: merupakan URL yg menunjukkan foto buku berukuran large


2. Ratings.csv

  Penjelasan mengenai variabel yang ada pada dataset Ratings.csv adalah sebagai berikut:

  - User-ID: merupakan id dari user
  - ISBN: merupakan kode ISBN dari buku
  - Book-Rating: merupakan rating buku yang diberikan user (rentang 1-10)


3. Users.csv

   Penjelasan mengenai variabel yang ada pada dataset Users.csv adalah sebagai berikut:

  - User-ID: merupakan id dari user
  - Location: merupakan lokasi dari user
  - Age: merupakan usia atau umur dari user

### Load dataset
"""

Books = pd.read_csv('/content/Books.csv')
Ratings = pd.read_csv('/content/Ratings.csv')
Users = pd.read_csv('/content/Users.csv')

"""### Melihat isi dataset books"""

Books.head()

"""### Eksplorasi dataset books"""

Books.info()

"""### Melihat isi dataset ratings"""

Ratings.head()

"""### Eksplorasi dataset ratings"""

Ratings.info()

"""### Melihat isi dataset users"""

Users.head()

"""### Eksplorasi dataset users"""

Users.info()

"""## **Data Preparation**

### Menggabungkan dataset books, ratings, dan users
"""

df1=Books.merge(Ratings,how="left", on="ISBN")
df_=df1.merge(Users,how="left", on="User-ID")

df=df_.copy()
df.head()

"""### Melihat jumlah baris dan kolom pada dataset yang telah digabungkan"""

df.shape

"""### Melihat jumlah data kosong pada setiap kolom"""

df.isna().sum()

"""### Mengecek apakah ada data yang terduplikat"""

duplicates = df[df.duplicated()]
len(duplicates)

"""### Visualisasi distribusi rating buku"""

rating_counter = df.groupby('Book-Rating').count()
plt.figure(figsize=(12,6))
plt.title('Book-Rating')
plt.xlabel('Rating')
plt.ylabel('Total Buku')
plt.bar(rating_counter.index, rating_counter['ISBN'])
plt.grid(True)
plt.show()

"""### Menghapus kategori yang tidak diperlukan pada kolom

Kategori yang dihapus adalah rating dengan nilai 0 pada variable Book-Rating. Alasan ketegori ini dihapus adalah karena menyebabkan data rating tidak seimbang.
"""

Ratings.shape

Ratings.drop(Ratings[Ratings["Book-Rating"] == 0].index, inplace=True)
Ratings.shape

"""### Visualisasi distribusi rating buku yang sudah ditangani data tidak seimbangnya"""

rating_counter = Ratings.groupby('Book-Rating').count()
plt.figure(figsize=(12,6))
plt.title('Jumlah Rating Buku yang Diberikan Pengguna')
plt.xlabel('Rating')
plt.ylabel('Jumlah Buku')
plt.bar(rating_counter.index, rating_counter['ISBN'])
plt.grid(True)
plt.show()

"""### Menghapus data yang mempunyai nilai null"""

all_book_clean = df.dropna()
all_book_clean

"""### Melihat data apakah masih ada kolom bernilai null atau tidak"""

all_book_clean.isnull().sum()

"""### Melakukan Encoding

Menyandikan (encode) fitur ‘User-ID’ ke dalam indeks integer.
"""

# Mengubah User-ID menjadi list tanpa nilai yang sama
user_ids = Ratings['User-ID'].unique().tolist()
print('list User-ID: ', user_ids)
 
# Melakukan encoding User-ID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User-ID : ', user_to_user_encoded)
 
# Melakukan proses encoding angka ke ke User-ID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke User-ID: ', user_encoded_to_user)

"""Menyandikan (encode) fitur ‘ISBN’ ke dalam indeks integer."""

# Mengubah ISBN menjadi list tanpa nilai yang sama
isbn_list = Ratings['ISBN'].unique().tolist()
 
# Melakukan proses encoding placeID
isbn_to_isbn_encoded = {x: i for i, x in enumerate(isbn_list)}
 
# Melakukan proses encoding angka ke placeID
isbn_encoded_to_isbn = {i: x for i, x in enumerate(isbn_list)}

"""Memetakan ‘User-ID’ dan ‘ISBN’ ke dataframe yang berkaitan."""

# Mapping User-ID ke dataframe user
Ratings['user'] = Ratings['User-ID'].map(user_to_user_encoded)
 
# Mapping ISBN ke dataframe book
Ratings['book'] = Ratings['ISBN'].map(isbn_to_isbn_encoded)

"""Mengecek beberapa hal dalam data seperti jumlah user, jumlah isbn, kemudian mengubah nilai rating menjadi float."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# Mendapatkan jumlah isbn
num_isbn = len(isbn_encoded_to_isbn)
print(num_isbn)
 
# Mengubah rating menjadi nilai float
all_book_clean['Book-Rating'] = all_book_clean['Book-Rating'].values.astype(np.float32)
 
# Nilai minimum Book-Rating
min_rating = min(all_book_clean['Book-Rating'])
 
# Nilai maksimal Book-Rating
max_rating = max(all_book_clean['Book-Rating'])
 
print('Number of User: {}, Number of ISBN: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_isbn, min_rating, max_rating
))

"""### Melakukan Pengacakan Data"""

# Mengacak dataset
all_book_clean = Ratings.sample(frac=1, random_state=42)
all_book_clean

"""### Membagi dataset

Memetakan (mapping) data user dan book menjadi satu value terlebih dahulu. Lalu, buatlah rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training.


Setelah itu bagi dataset. 80% untuk data train, dan 20% untuk data validasi.
"""

# Membuat variabel x untuk mencocokkan data user dan book menjadi satu value
x = all_book_clean[['user', 'book']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = all_book_clean['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * all_book_clean.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""### Membangun Model

Pada tahap ini, model menghitung skor kecocokan antara user dan ISBN dengan teknik embedding.

Pertama, kita melakukan proses embedding terhadap data user dan ISBN. 

kemudian melakukan operasi perkalian dot product antara embedding user dan ISBN. 

Selain itu, dapat juga menambahkan bias untuk setiap user dan ISBN. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.

Membuat class RecommenderNet dengan keras Model class.
"""

class RecommenderNet(tf.keras.Model):
 
      # Insialisasi fungsi
      def __init__(self, num_users, num_isbn, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_isbn = num_isbn
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding( # layer embedding user
            num_users,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
        self.book_embedding = layers.Embedding( # layer embeddings book
            num_isbn,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.book_bias = layers.Embedding(num_isbn, 1) # layer embedding book bias
    
      def call(self, inputs):
        user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
        user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
        book_vector = self.book_embedding(inputs[:, 1]) # memanggil layer embedding 3
        book_bias = self.book_bias(inputs[:, 1]) # memanggil layer embedding 4
    
        dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
    
        x = dot_user_book + user_bias + book_bias
        
        return tf.nn.sigmoid(x) # activation sigmoid

"""Melakukan proses compile terhadap model"""

model = RecommenderNet(num_users, num_isbn, 50) # inisialisasi model

        # model compile
        model.compile(
            loss = tf.keras.losses.BinaryCrossentropy(),
            optimizer = keras.optimizers.Adam(learning_rate=0.001),
            metrics=[tf.keras.metrics.RootMeanSquaredError()]
        )

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam sebagai optimizer, dan RMSE sebagai metrics evaluation.

### Melatih Model
"""

# Memulai training
        
        history = model.fit(
            x = x_train,
            y = y_train,
            batch_size=64,
            epochs = 10,
            validation_data = (x_val, y_val)
        )

"""### Evaluation"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.grid(True)
plt.show()

"""### Membuat variabel book_unread sebagai daftar buku untuk direkomendasikan pada user

Variabel book_unread diperoleh dengan menggunakan operator bitwise (~) pada variabel book_read_by_user
"""

books_df = Books
df = pd.read_csv('/content/Ratings.csv')
 
# Mengambil sample user
user_id = df['User-ID'].sample(1).iloc[0]
book_read_by_user = df[df['User-ID'] == user_id]
 
# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html 
book_unread = books_df[~books_df['ISBN'].isin(book_read_by_user.ISBN.values)]['ISBN']
book_unread = list(
    set(book_unread)
    .intersection(set(isbn_to_isbn_encoded.keys()))
)
 
book_unread = [[isbn_to_isbn_encoded.get(x)] for x in book_unread]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_unread), book_unread)
)

"""Untuk memperoleh rekomendasi restoran, gunakan fungsi model.predict() dari library Keras """

Ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = Ratings.argsort()[-10:][::-1]
recommended_book_isbns = [
    isbn_encoded_to_isbn.get(book_unread[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Books with high ratings from user')
print('----' * 8)
 
top_book_user = (
    book_read_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
book_df_rows = books_df[books_df['ISBN'].isin(top_book_user)]
for row in book_df_rows.itertuples():
    print(row._3, "-", row._2)
 
print('----' * 8)
print('Top 10 book recommendation')
print('----' * 8)
 
recommended_books = books_df[books_df['ISBN'].isin(recommended_book_isbns)]
for row in recommended_books.itertuples():
    print(row._3, "-", row._2)

"""## **Terimakasih.**

## **Submission project kelas Machine Learning Terapan - 2022** 
"""